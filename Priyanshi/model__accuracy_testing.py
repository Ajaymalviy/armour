# -*- coding: utf-8 -*-
"""MODEL _ACCURACY_TESTING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZgHG-QTh4MisxDesAl16OWhcC-SGewdJ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import torch

"""
Timm: PyTorch Image Models (timm) is a library for state-of-the-art-image classification, containing a collection of image models, optimizers, schedulers, augmentations and much more.
"""
import timm

import torch.nn.functional as F
from torch import nn
from torch.utils.data import Dataset, DataLoader

from skimage import io
from sklearn.model_selection import train_test_split

"""
tqdm is a library that is used for creating Python Progress Bars. It gets its name from the Arabic name taqaddum, which means 'progress. '
"""
from tqdm import tqdm


import os
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class APN_Model(nn.Module):

    def __init__(self, emb_size = 512):
        super(APN_Model, self).__init__()

        self.efficientnet = timm.create_model('efficientnet_b0', pretrained=True)
        self.efficientnet.classifier = nn.Linear(in_features = self.efficientnet.classifier.in_features,
                                                out_features = emb_size)


    def forward(self, images):
        embeddings = self.efficientnet(images)
        return embeddings
model = APN_Model()
model.to(DEVICE)
def get_encoding_csv(model, anc_img_names):
    anc_img_names_arr = np.array(anc_img_names)
    encodings = []

    model.eval()
    with torch.no_grad():
        for i in tqdm(anc_img_names_arr):
            A = io.imread(DATA_DIR +"/"+ i)
            A = torch.from_numpy(A).permute(2, 0, 1) / 255.0
            A = A. to(DEVICE)
            A_enc = model(A.unsqueeze(0)) # c,h,w --> (1,c,h,w)
            encodings.append(A_enc.squeeze().cpu().detach().numpy())

        encodings = np.array(encodings)
        encodings = pd.DataFrame(encodings)
        # Convert anc_img_names to a DataFrame for concatenation
        anc_img_names_df = pd.DataFrame(anc_img_names, columns=['Anchor'])
        df_enc = pd.concat([anc_img_names_df, encodings], axis=1)

    return df_enc
# DATA_DIR="/content/Market-1501-v15.09.15/query"
# query_img_names = [file for file in os.listdir('/content/Market-1501-v15.09.15/query') if file.endswith('.jpg')]
# query_df = get_encoding_csv(model, query_img_names)
# query_df.to_csv("query_database.csv", index=False)
# DATA_DIR="/content/Market-1501-v15.09.15/bounding_box_test"
# gallery_img_names = [file for file in os.listdir('/content/Market-1501-v15.09.15/bounding_box_test') if file.endswith('.jpg')]
# gallery_df = get_encoding_csv(model, gallery_img_names)
# gallery_df.to_csv("gallery_database.csv", index=False)
query_df = pd.read_csv("query_database.csv")
gallery_df = pd.read_csv("gallery_database.csv")
def calculate_cmc(query_df, gallery_df, top_k=10):
    query_encodings = query_df.iloc[:, 1:].to_numpy()
    gallery_encodings = gallery_df.iloc[:, 1:].to_numpy()

    correct_matches = 0
    total_queries = query_df.shape[0]

    for i, row in tqdm(query_df.iterrows(), total=query_df.shape[0]):
        query_img_name = row[0]
        # Extract the ID of the person from the query image name (assuming a specific format)
        query_id = query_img_name.split('_')[0]

        query_enc = query_encodings[i].reshape(1, -1)
        distances = np.linalg.norm(gallery_encodings - query_enc, axis=1)
        closest_idx = np.argsort(distances)[:top_k]

        # Check if any of the top-k closest images have the same ID as the query image
        for idx in closest_idx:
            gallery_img_name = gallery_df.iloc[idx, 0]
            gallery_id = gallery_img_name.split('_')[0]
            if query_id == gallery_id:
                correct_matches += 1
                break  # Move to the next query if a match is found

    recall_at_k = correct_matches / total_queries
    return recall_at_k
recall_at_k_value = calculate_cmc(query_df, gallery_df, top_k=10)
print(f"Recall@10: {recall_at_k_value:.4f}")